{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ewMscFUCGD8o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogLeNet은 Inception module이라는 블록을 가지고 있어서 인셉션 네트워크라고도 불리움.  \n",
        "1*1 filter 활용으로 연산량 down -> inception 내부에서 3*3, 5*5 전에 수행.  \n",
        "auxiliary는 중간중간 마지막 단의 분류 네트워크에서 발생한 손실이 입력 단까지 전달 안 되는 것을 막기 위함."
      ],
      "metadata": {
        "id": "x-V1hJgZGwI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_1(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, out_dim, 1, 1),\n",
        "      nn.ReLU()\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_1_3(in_dim, mid_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(mid_dim, out_dim, 3, 1, 1),\n",
        "      nn.ReLU()\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def conv_1_5(in_dim, mid_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.Conv2d(in_dim, mid_dim, 1, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(mid_dim, out_dim, 5, 1, 2),\n",
        "      nn.ReLU()\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def max_3_1(in_dim, out_dim):\n",
        "  model = nn.Sequential(\n",
        "      nn.MaxPool2d(3,1,1),\n",
        "      nn.Conv2d(in_dim, out_dim, 1, 1),\n",
        "      nn.ReLU()\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "7Fr33bDAGpN1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래는 PyTorch 공식 GoogLeNet"
      ],
      "metadata": {
        "id": "1OMbZekrXbdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class inception_module(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim_1,mid_dim_3, out_dim_3, mid_dim_5, out_dim_5, pool):\n",
        "    super(inception_module, self).__init__()\n",
        "\n",
        "    self.conv_1 = conv_1(in_dim, out_dim_1)\n",
        "    self.conv_1_3 = conv_1_3(in_dim, mid_dim_3, out_dim_3)\n",
        "    self.conv_1_5 = conv_1_5(in_dim, mid_dim_5, out_dim_5)\n",
        "    self.max_3_1 = max_3_1(in_dim, pool)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out_1 = self.conv_1(x)\n",
        "    out_2 = self.conv_1_3(x)\n",
        "    out_3 = self.conv_1_5(x)\n",
        "    out_4 = self.max_3_1(x)\n",
        "    output = torch.cat([out_1, out_2, out_3, out_4],1)#합치기\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "NcjxelZKWYRi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, base_dim, num_classes=2):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(3, base_dim, 7,2,3),\n",
        "        nn.MaxPool2d(3,2,1),\n",
        "        nn.Conv2d(base_dim, base_dim*3, 3, 1, 1),\n",
        "        nn.MaxPool2d(3,2,1)\n",
        "    )\n",
        "    self.layer_2 = nn.Sequential(\n",
        "        inception_module(base_dim*3, 64, 96, 128, 16, 32, 32),\n",
        "        inception_module(base_dim*4, 128, 128, 192, 32, 96, 64),\n",
        "        nn.MaxPool2d(3,2,1)\n",
        "    )\n",
        "    self.layer_3 = nn.Sequential(\n",
        "        inception_module(480, 192, 96, 208, 16, 48, 64),\n",
        "        inception_module(512, 160, 112, 224, 24, 64, 64),\n",
        "        inception_module(512, 128, 128, 256, 24, 64, 64),\n",
        "        inception_module(512, 112, 114, 288, 32, 64, 64),\n",
        "        inception_module(528, 256, 160, 320, 32, 128, 128),\n",
        "        nn.MaxPool2d(3,2,1)\n",
        "    )\n",
        "    self.layer_4 = nn.Sequential(\n",
        "        inception_module(832, 256, 160, 320, 32, 128, 128),\n",
        "        inception_module(832, 384, 192, 384, 48, 128, 128),\n",
        "        nn.AvgPool2d(7,1)\n",
        "    )\n",
        "    self.layer_5 = nn.Dropout2d(0.4)\n",
        "    self.fc_layer = nn.Linear(1024,1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer_1(x)\n",
        "    out = self.layer_2(out)\n",
        "    out = self.layer_3(out)\n",
        "    out = self.layer_4(out)\n",
        "    out = self.layer_5(out)\n",
        "\n",
        "    out = out.view(batch_size, -1)\n",
        "    out = self.fc_layer(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "kgCu8eGaYRxg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CbpeW6PRacTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}